# Data input pathways

<!-- TODO: Others? -->

## Pre- and post-processing of data

Any automated processing that is developed specific to a project would
need to adhere to the API's conventions. If any issues are found or if
the data is entirely new to the database, they get sent to a log and
User 4 would receive a notification to deal with the issue.

## Data, metadata, and expected values input

### Quality control

Any new or updated data that is uploaded would trigger generic automated
data cleaning, processing, quality control checks of this new data.

qc could be based on basic things like checking if file is correct,
contains proper delims, etc.

<!-- TODO: Would there be a QC for streaming data? -->

## From input to storage

### Flow for "sample analysis" data

```{mermaid}
%%| eval: true
%%| label: fig-data-input-sample-analysis
%%| fig-cap: "The flow of sample analysis-type data through Seedcase."
%%| file: images/data-input-sample-analysis.mmd
```

### Flow for batch data

```{mermaid}
%%| eval: true
%%| label: fig-data-input-batch
%%| fig-cap: "The flow of batch collection data through Seedcase."
%%| file: images/data-input-batch.mmd
```
